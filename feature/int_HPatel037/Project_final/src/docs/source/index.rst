Email Spam or Ham Checker
=========================

A complete end-to-end machine learning pipeline by **H.Patel** that detects whether an email is **Spam** or **Ham** using TF-IDF features and three classic ML algorithms.  
This documentation was generated automatically with Sphinx and includes data processing, model training, and evaluation details.

---

ğŸ“‚ Project Overview
-------------------

**Project Name:** Email Spam or Ham Checker  
**Author:** H.Patel  
**Version:** 1.0  
**Environment:** PFvenv (Python 3.10+)  

This project performs:
1. Data ingestion and cleaning  
2. TF-IDF feature extraction  
3. Model training (Logistic Regression, Linear SVM, Random Forest)  
4. MLflow experiment tracking  
5. Model evaluation and storage  
6. Interactive Streamlit App for predictions  

---

ğŸ“Š Data Description
-------------------

- Dataset 1 â†’ ``data/combined_dataset.csv``  
- Dataset 2 â†’ ``data/enron_spam_data.csv``  
- Merged output â†’ ``data/merged_spam.csv``  

The merged dataset contains thousands of email texts labeled as *Spam* (1) or *Ham* (0).  
All preprocessing removes duplicates, converts text to lowercase, and drops missing values.

---

âš™ï¸ Training Workflow
---------------------

1. **Merge Datasets**  
   Combines ``combined_dataset.csv`` and ``enron_spam_data.csv`` â†’ ``merged_spam.csv``.  

2. **Configuration**  
   Loaded from ``params.yaml`` and updated dynamically during runtime.  

3. **TF-IDF Vectorization**  
   Uses unigrams and bigrams with parameters:  
   - `min_df=2`  
   - `max_df=0.95`  
   - `ngram_range=(1, 2)`  

4. **Model Training**  
   Trains and evaluates:  
   - Logistic Regression  
   - Linear SVM  
   - Random Forest  
   Each model runs ``GridSearchCV`` and logs metrics to MLflow.  

5. **Model Saving**  
   All trained models and vectorizers are saved in the ``model/`` directory.  

6. **Prediction**  
   The predictor loads ``vectorizer.joblib`` and ``*_model.joblib`` to classify new emails as **Spam** or **Ham**.

---

ğŸ“ˆ Evaluation Metrics
---------------------

Each model logs metrics via MLflow, including:

- Accuracy  
- Precision  
- Recall  
- F1 Score  

A comparison report is printed after training to identify the **best model by F1 score**.

---

ğŸ§  Example: Training Commands
-----------------------------

.. code-block:: bat

   cd C:\Users\Owner\OneDrive\Desktop\final_final_project\Project_final
   python main.py
   REM trains models, merges datasets, and logs results to MLflow

   python -m src.models.predict
   REM test a single email input using a saved model

---

ğŸ’¾ File Structure Summary
-------------------------

.. code-block:: text

   FINAL_FINAL_PROJECT/
   â”œâ”€â”€ PFvenv/
   â”œâ”€â”€ Project_final/
   â”‚   â”œâ”€â”€ app/
   â”‚   â”‚   â””â”€â”€ streamlit_app.py
   â”‚   â”œâ”€â”€ data/
   â”‚   â”‚   â”œâ”€â”€ combined_dataset.csv
   â”‚   â”‚   â”œâ”€â”€ enron_spam_data.csv
   â”‚   â”‚   â””â”€â”€ merged_spam.csv
   â”‚   â”œâ”€â”€ model/
   â”‚   â”‚   â”œâ”€â”€ rf_model.joblib
   â”‚   â”‚   â”œâ”€â”€ logreg_model.joblib
   â”‚   â”‚   â”œâ”€â”€ linearsvc_model.joblib
   â”‚   â”‚   â””â”€â”€ vectorizer.joblib
   â”‚   â”œâ”€â”€ src/
   â”‚   â”‚   â”œâ”€â”€ data/make_dataset.py
   â”‚   â”‚   â”œâ”€â”€ models/tri_model_trainer.py
   â”‚   â”‚   â”œâ”€â”€ models/predict.py
   â”‚   â”‚   â””â”€â”€ main.py
   â”‚   â”œâ”€â”€ params.yaml
   â”‚   â””â”€â”€ requirements.txt

---

ğŸ’¡ How to View Results
-----------------------

1. After running ``python main.py``, open your MLflow UI:
   .. code-block:: bat
      mlflow ui

2. Then visit in your browser:
   http://localhost:5000

   Youâ€™ll see model runs, parameters, and metrics.

---

ğŸ§© Interactive App
------------------

To run the **Streamlit App** (optional GUI):
.. code-block:: bat

   cd Project_final/app
   streamlit run streamlit_app.py

---

ğŸ“š API Reference
----------------
.. toctree::
   :maxdepth: 2
   :caption: Source Code Modules

   api/modules
